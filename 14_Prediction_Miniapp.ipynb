{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binhvd/Data-Analytics-3-Labs/blob/main/14_Prediction_Miniapp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNZaPRLE8E1g"
      },
      "source": [
        "# Building a prediction \"miniapp\"\n",
        "\n",
        "Assuming we have already successfully trained a model for image classification (or in our case someone else did on [ImageNet](https://image-net.org/) and made it available for download [here](https://www.tensorflow.org/api_docs/python/tf/keras/applications)), we would like to build up a minimalistic web based \"application\" (basically a webpage in static HTML) that can accept an image upload and return the top 3 predictions in a really \"bare bones\" format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SBzH2mY8E1h"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "We will use the minimalist Python webserver [Flask](https://flask.palletsprojects.com/en/2.0.x/) to build our solution.\n",
        "\n",
        "As for easy accessibility through Colab (aka. \"someone else's computer\") we use [Ngrok](https://ngrok.com/) to expose our work to be available from \"outside\" the Colab machine, that is, thorough our browser. Luckily, we don't have to deal to much with this, we just use the [Flask-Ngrok](https://github.com/gstaff/flask-ngrok) package, that handles the hassle for us. Only thing to keep in mind is, that if we run the notebook in Colab, the solution we build will __only be reachable via the ugly looking Ngrok link__, not the \"localhost\" or \"127.0.0.1\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOv_Cc9EpbVd"
      },
      "outputs": [],
      "source": [
        "!pip install flask --quiet\n",
        "!pip install flask-ngrok --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwOtg13f8E1i"
      },
      "source": [
        "Fro image formatting we will use the [PIL](https://pillow.readthedocs.io/en/stable/) Python Imaging Library and [Numpy](https://numpy.org/) is always nice to have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zmjk5K26mT9"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tci-g2GF8E1i"
      },
      "source": [
        "## Downloading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJxW3wPVq8m0"
      },
      "outputs": [],
      "source": [
        "from  tensorflow.keras.applications.vgg16 import VGG16 \n",
        "from tensorflow.keras.applications.vgg16 import decode_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FaziY2OrRDk",
        "outputId": "f179f556-f218-4d60-e835-40b29572ce79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-05 11:43:16.972209: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-12-05 11:43:16.972458: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-12-05 11:43:16.973769: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        }
      ],
      "source": [
        "model = VGG16()\n",
        "# Luckily, the instantiation of a pretrained model obejct\n",
        "# does a complete download in the background\n",
        "# then initializes the model with the pretrained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDZijTRw8E1j"
      },
      "source": [
        "## Image preprocessing and prediction functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU93x_M76JBD"
      },
      "outputs": [],
      "source": [
        "import sys, json\n",
        "\n",
        "def load_image(filename):\n",
        "    \"\"\"Given a filename, assuming it is an image, we load it from disc.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : str\n",
        "        Name of input file.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    PIL Image object\"\"\"\n",
        "\n",
        "    ....\n",
        "    #TODO: use the Image class we imported from PIL to load the image.\n",
        "    #Keep it simple!\n",
        "        \n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QskFXgSi8E1k"
      },
      "outputs": [],
      "source": [
        "def resize_image(image):\n",
        "    \"\"\"Given a PIL image object we resize it to fit into our downloaded model.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    image : PIL Image object\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    PIL Image object\"\"\"\n",
        "    model_accepted_shape = model.inputs[0].shape[1:3] #ugly magic to get input shape from model\n",
        "    ....\n",
        "    #TODO: please use the shape above to reshape the image with PIL and return the image object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adbu1stl8E1k"
      },
      "outputs": [],
      "source": [
        "def to_numpy(image):\n",
        "    \"\"\"Given a PIL image object we convert it to a Numpy array.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    image : PIL Image object\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Numpy.Ndarray\"\"\"\n",
        "    array = np.array(image) \n",
        "    #Observe: Numpy is intelligent enough to accept a PIL object as input\n",
        "    #and convert it\n",
        "    return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mop8yYx48E1k"
      },
      "outputs": [],
      "source": [
        "def check_channels(array):\n",
        "    \"\"\"Given a numpy tensor we check for it's dimensionality, \n",
        "    and if too many channels are there, we drop 1.\n",
        "    This can be necessary in case of certain PNG images having additional channels.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    array : Ndarray\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Numpy.Ndarray\"\"\"    \n",
        "    if array.shape[2]>3:\n",
        "        array = array[:,:,:3]\n",
        "    #Ugly magic to drop a channel - the last one - in cease there are too many\n",
        "    return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNUVC9hi8E1k"
      },
      "outputs": [],
      "source": [
        "def create_batch(array):\n",
        "    \"\"\"Given a numpy tensor we create a single element \"batch\" from it by adding a dimension.\n",
        "    This is necessary because the model was trained with \"minibatches\" of data,\n",
        "    so it assumes, that it does not get one single unput, but a bunch of them at once.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    array : Ndarray\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Numpy.Ndarray\"\"\" \n",
        "    TODO\n",
        "    batch = .... #You have to extend the dimensionality of the input...\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCD2F7V38E1k"
      },
      "outputs": [],
      "source": [
        "def execute_prediction(batch, model):\n",
        "    \"\"\"Given a numpy tensor representing the \"batch\" and the loaded model object, \n",
        "    we execute the prediction.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    batch : Ndarray,\n",
        "    model : TF.Keras.model\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    prediction in Keras model's own format\"\"\" \n",
        "    TODO\n",
        "    prediction = .... #Use the appropriate method of the model on the data\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieeQJEts8E1l"
      },
      "outputs": [],
      "source": [
        "def interpret_prediciton(prediction):\n",
        "    \"\"\"Given Keras model's prediction, we parse it and select the top 3.\n",
        "    For this ve utilize the default `decode_predictions` function of TF.Keras\n",
        "    For more info, see https://www.tensorflow.org/api_docs/python/tf/keras/applications/imagenet_utils/decode_predictions\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    array : Keras model's prediction\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary containing the top 3 predictions.\"\"\" \n",
        "    label = decode_predictions(prediction)\n",
        "    decoded_prediction = []\n",
        "    # retrieve the most likely result, e.g. highest probability\n",
        "    for l in label[0][:3]:\n",
        "        print('%s (%.2f%%)' % (l[1], round(l[2]*100,2)))\n",
        "        #some nice formatting to dicts\n",
        "        decoded_prediction.append({\"class\": l[1], \"probability\":round(l[2]*100,2)})\n",
        "    return decoded_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URYIN2TQ8E1l"
      },
      "outputs": [],
      "source": [
        "def human_format_prediction(decoded_prediction):\n",
        "    \"\"\"Given the processed prediction dict, we modify it to look nice to people\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dict : Interpreted prediction top 3\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        A string representing human readable output.\"\"\" \n",
        "    formatted_output = \"\"\n",
        "    for element in decoded_prediction:\n",
        "        formatted_output += str(element)\n",
        "        formatted_output += \"<br>\" #some nice line breaks in HTML rendering\n",
        "    return formatted_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJujECyv8E1l"
      },
      "outputs": [],
      "source": [
        "def json_format_prediction(decoded_prediction):\n",
        "    \"\"\"Given the processed prediction dict, we modify it to become proper JSON\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dict : Interpreted prediction top 3\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        A JSON conformant string representing of the output.\"\"\"\n",
        "    return json.dumps(decoded_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdX5O06t8E1l"
      },
      "outputs": [],
      "source": [
        "def do_prediction(filename):\n",
        "    \"\"\"Main prediction function. \n",
        "    - Takes in a filename, \n",
        "    - calls preprocessing steps, \n",
        "    - returns formatted prediction.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : str\n",
        "        Name of input file.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        A string representingoutput.\"\"\"    \n",
        "    image = load_image(filename)\n",
        "    image = resize_image(image)\n",
        "    array = to_numpy(image)\n",
        "    array = check_channels(array)\n",
        "    batch = create_batch(array)\n",
        "    prediction = execute_prediction(batch, model)\n",
        "    decoded_prediction = interpret_prediciton(prediction)\n",
        "    formatted_output = human_format_prediction(decoded_prediction)\n",
        "    return formatted_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkzUWktw3EvB"
      },
      "source": [
        "Please observe, that the model will systemmatically err in the direction fo \"slim\" dog breeds, because the way we implemented \"resize\" of the original image - ie. we \"squeeze\" te image to conform to 224x224 pixels!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6pUZ2D38E1l"
      },
      "source": [
        "## Flask app\n",
        "\n",
        "Since we have nice functions that can take in an image and return a prediction, we can now start to develop the mini \"webapp\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBRNcgD78E1l"
      },
      "source": [
        "### Basic HTML page\n",
        "\n",
        "Let's first define a basic HTML page layout tha thas a single control element: an upload \"form\" which can take in files via the browser. This will be our way to feed in the inputs for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8Lf85df4Fxg"
      },
      "outputs": [],
      "source": [
        "HTML = \"\"\"\n",
        "<!doctype html>\n",
        "<html>\n",
        "  <head>\n",
        "    <title>File Upload</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <h1>File Upload</h1>\n",
        "    <form method=\"POST\" action=\"\" enctype=\"multipart/form-data\">\n",
        "      <p><input type=\"file\" name=\"file\"></p>\n",
        "      <p><input type=\"submit\" value=\"Submit\"></p>\n",
        "    </form>\n",
        "  </body>\n",
        "</html>\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WioWTV3O8E1m"
      },
      "source": [
        "### \"Main app\"\n",
        "\n",
        "Now we define a minimalistic Flask app, that defines single page endpoint at \"/\", so the root URL. \n",
        "\n",
        "If a HTTP (\"GET\") request comes in to this URL, the app will automatically respond by \"serving\" the HTML content we difend above, so the requesting browser can render the \"webpage\" we built.\n",
        "\n",
        "After this the user is free to interact with our wonderful form to choose an appropriate image file. We are assuming here that the user acts non-maliciously, so we do not do all the checks for file content and structure that would protect us, just assume, that the user uploads well behaving image files. \n",
        "\n",
        "When the user pushes \"Submit\", this automatically generates a \"POST\" HTTP request towards our Flask app's \"/\" or \"root\" endpoint and with it, it \"posts\" or sends the image file, which we handle by defining an `upload_file` endpoint, that saves the file and calls on it the `do_prediction` function we defined above. (Please observe, that we don't care about the saved files, so they might accumuate, collide...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJq8r9_hprWN"
      },
      "outputs": [],
      "source": [
        "from flask import *\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "#TODO Use the Flask guide to define the simplest possible endpoint for the \"root url\"\n",
        "@....\n",
        "def ....:\n",
        "    return ....\n",
        "\n",
        "#TODO Use the Flask guide to define a POST endpoint for the \"root url\"\n",
        "@....\n",
        "def upload_file():\n",
        "    uploaded_file = request.files['file']\n",
        "    if uploaded_file.filename != '':\n",
        "        uploaded_file.save(uploaded_file.filename)\n",
        "\n",
        "    result = .....#TODO use the main prediction function from above to generate the result\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLzunDBC8E1m"
      },
      "source": [
        "And finally we start running our \"web application\" via the Ngrok tunnel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "JEnIz4_UpzED",
        "outputId": "ac316866-45e2-4054-d44a-435a82f485ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__' (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://63d5-45-86-201-148.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Dec/2021 11:43:31] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Dec/2021 11:43:32] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "2021-12-05 11:43:40.379966: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-12-05 11:43:40.404002: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2803200000 Hz\n",
            "127.0.0.1 - - [05/Dec/2021 11:43:40] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weimaraner (35.70%)\n",
            "Labrador_retriever (23.50%)\n",
            "clumber (10.82%)\n"
          ]
        }
      ],
      "source": [
        "run_with_ngrok(app)\n",
        "app.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiVrjEC08E1m"
      },
      "source": [
        "In case local execution fails, [this](https://githubmemory.com/repo/gstaff/flask-ngrok/issues/20) might help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2GwX_Ym8E1m"
      },
      "source": [
        "# Testing\n",
        "\n",
        "Please open the temporary ngrok.io link that is visible in the cell output, grab a pictrure from somewhere (eg. an image of a dog) and use the submit functionality! \n",
        "\n",
        "After a single prediction, you can get back to the main form with the back button."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Flask_example.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}